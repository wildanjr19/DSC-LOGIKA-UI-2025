{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GHb2wicyXL5"
   },
   "source": [
    "# DATASET YANG DIGUNAKAN\n",
    " https://kaggle.com/datasets/77f50ecd6c0ec5fa1d3a7f5b5fc3db4273262732ab29ab709341f2e0fd707b97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWdPI9ivva9O"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "<br>\n",
    "<h1 style=\"font-family:verdana; font-size:26px\"> <center>~ Notebook Penyisihan DSC LOGIKA UI 2025 ~</center> </h1>\n",
    "<br>\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "# **LPK - Mak Gorengno Ndoog**\n",
    "\n",
    "<p style = \"font-size:16px; font-family:verdana\">- Nugroho Ardiyanto (Leader)<p>\n",
    "\n",
    "<p style = \"font-size:16px; font-family:verdana\">- Wildan Abid Al Hanif\n",
    " <p>\n",
    "\n",
    "<p style = \"font-size:16px; font-family:verdana\">- Andra Hanandaru <p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU44zBJkzRDx"
   },
   "source": [
    "<style>\n",
    "hr.mustard {\n",
    "  border: 2px solid #FFB300;\n",
    "  margin-top: 12px;\n",
    "  margin-bottom: 12px;\n",
    "}\n",
    "h1, h2, h3 {\n",
    "  color: #FFB300;\n",
    "  font-family: \"Segoe UI\", sans-serif;\n",
    "}\n",
    "p {\n",
    "  font-size: 16px;\n",
    "  line-height: 1.6;\n",
    "}\n",
    "blockquote {\n",
    "  background: #FFF9C4;\n",
    "  border-left: 6px solid #FFB300;\n",
    "  margin: 10px 0;\n",
    "  padding: 10px 15px;\n",
    "  font-style: italic;\n",
    "}\n",
    "code {\n",
    "  background-color: #FFF3CD;\n",
    "  color: #333;\n",
    "  padding: 3px 6px;\n",
    "  border-radius: 4px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "# üè† **Overview: Kompetisi Klasifikasi Rumah Adat Nusantara**\n",
    "\n",
    "Seiring dengan semakin berkurangnya pengetahuan generasi muda tentang rumah adat, upaya pelestarian budaya menjadi semakin penting. Kompetisi Klasifikasi Rumah Adat Nusantara ini memberi kesempatan bagi peserta untuk membangun model yang mampu mengenali berbagai rumah adat dari seluruh Indonesia. Dataset yang digunakan berisi ribuan citra rumah adat dari berbagai daerah dengan variasi pencahayaan, sudut pandang, dan kualitas gambar. Dengan menerapkan teknik data science, peserta dapat menggali wawasan baru tentang pola visual arsitektur Nusantara sekaligus berkontribusi dalam upaya digitalisasi dan pelestarian warisan budaya bangsa.\n",
    "\n",
    "<hr class=\"mustard\">\n",
    "\n",
    "# üéØ **Objektif Kompetisi**\n",
    "\n",
    "Kurangnya pengetahuan tentang rumah adat Nusantara dapat mengakibatkan hilangnya identitas budaya dan warisan arsitektur yang berharga. Dalam kompetisi ini, peserta diharapkan dapat membangun model yang mampu mengklasifikasikan setiap gambar ke dalam kategori rumah adat yang tepat dengan tingkat akurasi dan generalisasi yang tinggi.\n",
    "\n",
    "<hr class=\"mustard\">\n",
    "<hr class=\"mustard\">\n",
    "\n",
    "# üéØ **Tujuan Kompetisi**\n",
    "\n",
    "Tujuan dari kompetisi ini adalah mendorong para peserta untuk mengasah keterampilan mereka dalam bidang data science khususnya computer vision. Dengan berpartisipasi, peserta turut berkontribusi pada pelestarian budaya Nusantara dengan membantu mengenali dan mendokumentasikan keragaman arsitektur tradisional Indonesia. Selain meningkatkan kemampuan teknis, kompetisi ini juga menekankan pentingnya pemanfaatan teknologi berbasis data untuk mendukung upaya pelestarian warisan budaya di era digital.\n",
    "\n",
    "<hr class=\"mustard\">\n",
    "\n",
    "# üìè **Metriks Pengukuran**\n",
    "\n",
    "Submisi dinilai berdasarkan **Macro F1-Score** yang menyatakan rata-rata F1-Score per kelas. Secara matematis, Macro F1-Score dihitung dengan:\n",
    "\n",
    "**Macro F1 = (1 / N) √ó Œ£ [ (2 √ó Precision·µ¢ √ó Recall·µ¢) / (Precision·µ¢ + Recall·µ¢) ]**\n",
    "\n",
    "\n",
    "dengan:\n",
    "\n",
    "- **Precision·µ¢ = TP·µ¢ / (TP·µ¢ + FP·µ¢)**  \n",
    "- **Recall·µ¢ = TP·µ¢ / (TP·µ¢ + FN·µ¢)**  \n",
    "\n",
    "\n",
    "> üí° *Metrik ini dipilih karena dataset memiliki distribusi kelas yang cukup tidak seimbang, sehingga metrik biasa seperti accuracy dapat menyesatkan. Macro F1-Score mengatasi masalah ini dengan memberikan bobot yang sama pada setiap kelas, sehingga model didorong untuk berperforma baik pada semua kategori rumah adat.*\n",
    "\n",
    "<hr class=\"mustard\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AaHnnaLHNUi"
   },
   "source": [
    "# üè† Deskripsi Dataset: Rumah Adat Indonesia\n",
    "\n",
    "Dataset ini berisi kumpulan **gambar rumah adat dari berbagai daerah di Indonesia**, yang masing-masing dilengkapi dengan **label kategori** sesuai asal daerahnya.  \n",
    "Label tersebut digunakan sebagai **target (kelas)** untuk membangun dan melatih **model klasifikasi citra (image classification)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Kategori Rumah Adat\n",
    "\n",
    "| **Kategori** | **Deskripsi** |\n",
    "|---------------|---------------|\n",
    "| **Javanese** | Mencakup rumah tradisional Jawa seperti **Joglo** dan **Kraton**, yang menonjolkan struktur atap tinggi dan filosofi tata ruang yang khas. |\n",
    "| **Balinese** | Rumah tradisional **Bali**, termasuk area **pura** dengan ornamen dan ukiran yang kaya simbol spiritual serta kental dengan budaya Hindu. |\n",
    "| **Minangkabau** | **Rumah Gadang** dari **Sumatra Barat**, terkenal dengan atap bergonjong yang melambangkan tanduk kerbau dan menjadi simbol adat Minang. |\n",
    "| **Batak** | **Rumah Bolon** dari **Sumatra Utara**, memiliki bentuk panggung dengan atap melengkung tinggi serta ukiran khas Batak. |\n",
    "| **Dayak** | **Rumah Panjang** khas masyarakat **Dayak** di **Kalimantan**, yang berfungsi sebagai tempat tinggal komunal dan pusat kegiatan adat. |\n",
    "\n",
    "---\n",
    "\n",
    "Dengan **label yang jelas dan terstruktur**, dataset ini memungkinkan pengguna untuk:\n",
    "\n",
    "- Melatih dan menguji berbagai **model klasifikasi citra**  \n",
    "- Mempelajari **keragaman arsitektur tradisional Indonesia**  \n",
    "- Mengembangkan **aplikasi edukatif** atau **sistem pengenalan rumah adat** berbasis kecerdasan buatan  \n",
    "\n",
    "---\n",
    "\n",
    "üí° *Dataset ini tidak hanya berguna untuk eksperimen machine learning, tetapi juga dapat memperkenalkan kekayaan budaya arsitektur Indonesia kepada dunia.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Hj5tFmj_Wc"
   },
   "source": [
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n",
    "\n",
    "# üß© Tahap 1 ‚Äî Sebelum *Preprocessing* Data\n",
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNXWTf5h0V_D"
   },
   "source": [
    "\n",
    "## Libraries\n",
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9Qcy1hVvaG-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import shutil\n",
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u01bHKYtJPvP"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Konfigurasi Data Asli\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7-SlzmUJV4U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = '/kaggle/input/'\n",
    "#base_path = '/kaggle/input/dataset-logika' (jika path yang atas menimbulkan error)\n",
    "train_dir = os.path.join(base_path, 'original-data/Train/Train')\n",
    "test_dir = os.path.join(base_path, 'original-data/Test/Test')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT5PiTLIlay_"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Set Seed untuk Reproduksibilitas\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_tG9eJvUt-k",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_D_cNMM0uTR"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Exploratory Data Analysis <a name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JGis6En09Op"
   },
   "source": [
    "> Exploratory Data Analysis (EDA) pada data citra merupakan proses untuk menelaah dan memahami karakteristik kumpulan gambar sebelum dilakukan pemodelan. Melalui EDA, peneliti dapat mengidentifikasi pola visual, variasi warna, pencahayaan, resolusi, serta distribusi jumlah gambar pada setiap kelas. Analisis ini juga membantu menemukan ketidakseimbangan kelas (class imbalance), gambar duplikat, atau citra yang rusak. Dengan menggunakan visualisasi seperti image grid, histogram warna, dan grafik distribusi label, EDA pada data citra memberikan pemahaman mendalam tentang kualitas dan keragaman data, yang menjadi dasar penting untuk tahap praproses dan pengembangan model klasifikasi selanjutnya.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt-G--tXFprF"
   },
   "source": [
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n",
    "### Cek Distribusi Label\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "xn8-Ol4zIaQm",
    "outputId": "e79831d4-85ff-4e3e-f7e9-80152f9d5738",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp_dataset = ImageFolder(train_dir)\n",
    "NUM_CLASSES = len(temp_dataset.classes)\n",
    "class_names = temp_dataset.classes\n",
    "class_counts = Counter([label for _, label in temp_dataset.imgs])\n",
    "\n",
    "print(\"\\nüìä Distribusi Kelas:\")\n",
    "for idx, cls_name in enumerate(class_names):\n",
    "    print(f\"   {cls_name:<15}: {class_counts[idx]} gambar\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_names, [class_counts[i] for i in range(len(class_names))], color='skyblue')\n",
    "plt.title(\"Distribusi Jumlah Gambar per Kelas (Train)\", fontsize=13)\n",
    "plt.xlabel(\"Kelas\", fontsize=11)\n",
    "plt.ylabel(\"Jumlah Gambar\", fontsize=11)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5uwgW4xFtHH"
   },
   "source": [
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n",
    "### Contoh Data Train Tiap Kelas\n",
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "te-V9jmRIapF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, cls in enumerate(class_names):\n",
    "    class_dir = os.path.join(train_dir, cls)\n",
    "    all_images = os.listdir(class_dir)\n",
    "\n",
    "    # Filter hanya gambar asli (bukan augmented)\n",
    "    original_images = [\n",
    "        img for img in all_images\n",
    "        if not any(aug in img.lower() for aug in [\"aug\", \"flip\", \"rot\", \"noise\", \"blur\", \"crop\"])\n",
    "    ]\n",
    "\n",
    "    if not original_images:  # fallback kalau semua gambar ternyata augmented\n",
    "        original_images = all_images\n",
    "\n",
    "    sample_img = random.choice(original_images)\n",
    "    img_path = os.path.join(class_dir, sample_img)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    plt.subplot(1, len(class_names), i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(cls)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Contoh Gambar Asli Tiap Kelas (Tanpa Augmentasi)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEhohhP_Fy9V"
   },
   "source": [
    "\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n",
    "### Contoh Data Test\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fgRoMXoIa_f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_images = os.listdir(test_dir)\n",
    "sample_test = random.sample(test_images, min(3, len(test_images)))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i, img_name in enumerate(sample_test):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Test {i+1}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Contoh 3 Gambar dari Data Test\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YjTaHy2prkv"
   },
   "source": [
    "### Hasil Analisis Data\n",
    "Dari proses eksplorasi data terlihat bahwa jumlah gambar pada setiap kelas **tidak merata (imbalanced)**, di mana beberapa kategori rumah adat memiliki jauh lebih banyak sampel dibandingkan kelas lainnya.  \n",
    "Selain itu, ditemukan pula **beberapa kesalahan pelabelan** pada data train, seperti gambar rumah adat yang ditempatkan pada kelas yang tidak sesuai dengan asal daerahnya.  \n",
    "Kondisi ini berpotensi menurunkan performa model karena dapat menyebabkan bias dalam proses pembelajaran.  \n",
    "Oleh karena itu, dilakukan serangkaian **tahap pre-processing** untuk memperbaiki struktur dataset, menyeimbangkan distribusi kelas, dan memastikan label setiap gambar sudah akurat sebelum digunakan dalam pelatihan model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW0TxTj-oxQc"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "# üß© Pre-processing Data\n",
    "\n",
    "Tahap **pre-processing** dilakukan untuk memastikan dataset memiliki kualitas tinggi, label yang akurat, serta variasi yang cukup sebelum digunakan dalam pelatihan model klasifikasi rumah adat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1r9GXuKXPg7"
   },
   "source": [
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "### üîπ Koreksi Label dan Pemindahan Data\n",
    "Selama tahap pemeriksaan, ditemukan beberapa gambar yang **memiliki label tidak tepat** (misalnya, gambar rumah adat dari satu daerah berada di folder kelas lain).  \n",
    "Gambar-gambar tersebut kemudian **dipindahkan secara manual** ke folder yang benar berdasarkan identifikasi ciri khas arsitektur, seperti:\n",
    "- Bentuk atap dan struktur bangunan  \n",
    "- Pola ukiran dan ornamen  \n",
    "- Material serta bentuk tiang penyangga  \n",
    "\n",
    "Langkah ini memastikan bahwa setiap kelas benar-benar merepresentasikan rumah adat yang sesuai.\n",
    "\n",
    "| file_name | correct_class | class |\n",
    "|------------|----------------|--------|\n",
    "| balinese_train_000651.jpg | javanese | balinese |\n",
    "| balinese_train_000760.jpg | batak | balinese |\n",
    "| balinese_train_000761.jpg | batak | balinese |\n",
    "| balinese_train_000762.jpg | batak | balinese |\n",
    "| balinese_train_000763.jpg | dayak | balinese |\n",
    "| ... | ... | ... |\n",
    "| minangkabau_train_000416.jpg | javanese | minangkabau |\n",
    "| minangkabau_train_000459.jpg | javanese | batak |\n",
    "| batak_train_000059.jpg | minangkabau | batak |\n",
    "| batak_train_000067.jpg | minangkabau | batak |\n",
    "| batak_train_000095.jpg | minangkabau | batak |\n",
    "\n",
    "üì¶ **Total data yang dipindahkan:** 71 gambar  \n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "\n",
    "### üîπ Penghapusan Data yang Tidak Sesuai\n",
    "Selain koreksi label, beberapa gambar juga **dihapus** dari dataset karena dianggap **tidak relevan atau tidak representatif**, misalnya:\n",
    "- Duplikat data\n",
    "- Gambar yang tidak sesuai dengan kelas yang ada  \n",
    "\n",
    "Penghapusan dilakukan untuk menjaga **kebersihan dan konsistensi data**, sehingga model tidak belajar dari contoh yang keliru.\n",
    "\n",
    "| file_name | class |\n",
    "|------------|--------|\n",
    "| balinese_train_000008.jpg | balinese |\n",
    "| balinese_train_000076.jpg | balinese |\n",
    "| balinese_train_000094.jpg | balinese |\n",
    "| balinese_train_000115.jpg | balinese |\n",
    "| balinese_train_000192.jpg | balinese |\n",
    "| ... | ... |\n",
    "| minangkabau_train_000336.jpg | minangkabau |\n",
    "| minangkabau_train_000378.jpg | minangkabau |\n",
    "\n",
    "üßæ **Total data yang dihapus:** 128 gambar  \n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "### üîπ Augmentasi Data Manual\n",
    "Untuk meningkatkan variasi dan memperkaya data pelatihan, dilakukan **augmentasi manual** yang bersumber dari data pelatihan yang disediakan, mencakup:\n",
    "- Crop gambar\n",
    "- Penambahan noise ringan  \n",
    "- Penyesuaian kecerahan dan kontras  \n",
    "\n",
    "Setiap hasil augmentasi disimpan dengan nama baru agar mudah dibedakan dan diawali dengan index 1 pada hasil augmentasi tiap kelas.\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "üìñ Dokumentasi lengkap proses dapat dilihat di repository berikut:  \n",
    "üîó [Data Preparation ‚Äì LOGIKA UI 2025](https://github.com/wildanjr19/LOGIKAUI2025/blob/main/data-preparation.ipynb)\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0kbWkSjtp6o"
   },
   "source": [
    "## Library\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdoSfEGAtokK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import shutil\n",
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1fv1NenqaJE"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Konfigurasi Folder Augmentasi\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4UxBL2kpFcX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = '/kaggle/input/'\n",
    "#base_path = '/kaggle/input/dataset-logika' (jika path yang atas menimbulkan error)\n",
    "aug_dir = os.path.join(base_path, 'augmented-image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa3AGS1OqebQ"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Visualisasi Hasil Augmentasi\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1BRSzlwqWXo",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_aug_images = []\n",
    "for root, _, files in os.walk(aug_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            all_aug_images.append(os.path.join(root, file))\n",
    "\n",
    "# Tampilkan 3 gambar acak\n",
    "if len(all_aug_images) > 0:\n",
    "    sample_images = random.sample(all_aug_images, min(3, len(all_aug_images)))\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(os.path.basename(img_path)[:25])  # tampilkan sebagian nama file\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Contoh 3 Gambar dari Folder Augmented\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tidak ada gambar yang ditemukan di folder 'augmented'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6obMgh-kdn8"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "# üß© Tahap 3 ‚Äî Sesudah *Preprocessing* Data\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6IeLtDntdYD"
   },
   "source": [
    "## LIbrary\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgrRyzOGte-q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import shutil\n",
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUFX1dZpmnGA"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Konfigurasi Data Setelah Preprocessing Data\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsrk8ESimlue",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = '/kaggle/input/'\n",
    "#base_path = '/kaggle/input/dataset-logika' (jika path yang atas menimbulkan error)\n",
    "train_dir = os.path.join(base_path, 'preproced-data/Train/Train')\n",
    "test_dir = os.path.join(base_path, 'preproced-data/Test/Test')\n",
    "IMG_SIZE = 448\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "temp_dataset = ImageFolder(train_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a3-DPzetKTf"
   },
   "source": [
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n",
    "## Pengaturan Seed untuk Reproduksibilitas\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rc3swDI-tHYR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIyZL_vBa0hW"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## DINOV2 Model (FROZEN FEATURE EXTRACTOR)\n",
    "\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ghtsn84NcGhi"
   },
   "source": [
    "### Load Model\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o57d5_RLVyPf",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dinov2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14')\n",
    "dinov2_model.eval()\n",
    "dinov2_model.to(device)\n",
    "\n",
    "# Freeze semua parameter (tidak akan di-train)\n",
    "for param in dinov2_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"‚úì DINOv2 ViT-G/14 loaded successfully\")\n",
    "print(\"‚úì Feature dimension: 1536\")\n",
    "print(\"‚úì Model frozen (tidak akan di-train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5vBztzacSAd"
   },
   "source": [
    "### Ekstraksi Fitur dari Data Train\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.031Z"
    },
    "id": "MN3nbf-rcf8J",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dinov2_transform = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE * 1.14)),  # Resize sedikit lebih besar\n",
    "    transforms.CenterCrop(IMG_SIZE),           # Crop ke ukuran target\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, image_folder_dataset, transform):\n",
    "        self.imgs = image_folder_dataset.imgs\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.imgs[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_dataset = SimpleImageDataset(temp_dataset, dinov2_transform)\n",
    "EXTRACT_BATCH_SIZE = 16 if IMG_SIZE >= 448 else 32 if IMG_SIZE >= 336 else 48\n",
    "print(f\"‚úì Extraction batch size: {EXTRACT_BATCH_SIZE} (disesuaikan dengan resolusi)\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=EXTRACT_BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "print(f\"üì¶ Extracting features dari {len(train_dataset)} gambar training...\")\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(train_loader, desc=\"Ekstraksi Fitur Training\"):\n",
    "        images = images.to(device)\n",
    "        features = dinov2_model(images)\n",
    "        all_features.append(features.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "# Gabungkan semua batch\n",
    "train_features = np.vstack(all_features)\n",
    "train_labels = np.concatenate(all_labels)\n",
    "\n",
    "print(f\"‚úì Features extracted: {train_features.shape}\")\n",
    "print(f\"‚úì Labels shape: {train_labels.shape}\")\n",
    "\n",
    "# Simpan features untuk reuse\n",
    "with open('train_features_dinov2.pkl', 'wb') as f:\n",
    "    pickle.dump({'features': train_features, 'labels': train_labels}, f)\n",
    "print(\"‚úì Features disimpan ke 'train_features_dinov2.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7znM1V4Pcv0E"
   },
   "source": [
    "## Persiapan Data untuk Training Classifier\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "VRkYz-pBdQZ6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert ke torch tensors\n",
    "train_features_tensor = torch.from_numpy(train_features).float()\n",
    "train_labels_tensor = torch.from_numpy(train_labels).long()\n",
    "\n",
    "# Dataset dari features\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "feature_dataset = FeatureDataset(train_features_tensor, train_labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL0HtmuDdQGy"
   },
   "source": [
    "## Split *Data*\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "zj62XcwZdUUd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = int(0.85 * len(feature_dataset))\n",
    "val_size = len(feature_dataset) - train_size\n",
    "train_subset, val_subset = random_split(feature_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "print(f\"‚úì Training samples: {train_size}\")\n",
    "print(f\"‚úì Validation samples: {val_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgiKmr7Debrv"
   },
   "source": [
    "## Penghitungan weight untuk handling imbalanced data\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "KQGkqQU5emPQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_samples = len(train_labels)\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (NUM_CLASSES * class_counts[i]) for i in range(NUM_CLASSES)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"‚úì Class weights computed: {class_weights.cpu().numpy()}\")\n",
    "\n",
    "# WeightedRandomSampler untuk balanced training\n",
    "train_labels_subset = [train_labels[idx] for idx in train_subset.indices]\n",
    "sample_weights = [class_weights[label].item() for label in train_labels_subset]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJymu9a-etyf"
   },
   "source": [
    "## Data Loader\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "7jJVmpOiew98",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_feat_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0, drop_last=True)\n",
    "val_feat_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(f\"‚úì DataLoaders ready (batch size: {BATCH_SIZE})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzpdX5l0e6fz"
   },
   "source": [
    "## Definisi Classifier Head\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "dqDLIN9hfObB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, input_dim=1536, num_classes=NUM_CLASSES, dropout=0.5):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "\n",
    "        # Initial projection\n",
    "        self.input_proj = nn.Linear(input_dim, 512)\n",
    "\n",
    "        # Residual Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512)\n",
    "        )\n",
    "\n",
    "        # Transition 1: 512 -> 256\n",
    "        self.trans1 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "\n",
    "        # Residual Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256)\n",
    "        )\n",
    "\n",
    "        # Transition 2: 256 -> 128\n",
    "        self.trans2 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "        # Residual Block 3\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.5),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128)\n",
    "        )\n",
    "\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout * 0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial projection\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # Residual Block 1 with skip connection\n",
    "        identity = x\n",
    "        x = self.block1(x) + identity\n",
    "        x = self.trans1(x)\n",
    "\n",
    "        # Residual Block 2 with skip connection\n",
    "        identity = x\n",
    "        x = self.block2(x) + identity\n",
    "        x = self.trans2(x)\n",
    "\n",
    "        # Residual Block 3 with skip connection\n",
    "        identity = x\n",
    "        x = self.block3(x) + identity\n",
    "\n",
    "        # Final classification\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "classifier = ClassifierHead(input_dim=1536, num_classes=NUM_CLASSES, dropout=0.5)\n",
    "classifier.to(device)\n",
    "\n",
    "print(f\"‚úì Classifier input dimension: 1536\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRqtlVRnfgaI"
   },
   "source": [
    "## Proses Training Classifier\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "3PqmdH-pfjVt",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss function dengan class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer & Scheduler\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=5e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 50\n",
    "best_f1 = 0.0\n",
    "patience = 12\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"üöÄ Starting training for {NUM_EPOCHS} epochs...\")\n",
    "print(f\"üìä Early stopping patience: {patience}\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TRAINING PHASE\n",
    "    classifier.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for features, labels in tqdm(train_feat_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\", leave=False):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(classifier.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100.0 * train_correct / train_total\n",
    "    avg_train_loss = train_loss / len(train_feat_loader)\n",
    "\n",
    "    # VALIDATION PHASE\n",
    "    classifier.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(val_feat_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\", leave=False):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_feat_loader)\n",
    "    val_acc = 100.0 * np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    # Update scheduler\n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nüìà Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"   Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(classifier.state_dict(), 'best_classifier_dinov2.pth')\n",
    "        print(f\"   ‚úÖ Best model saved! F1: {best_f1:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"   ‚è≥ No improvement ({patience_counter}/{patience})\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ Training selesai! Best F1-Score: {best_f1:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1ZAtzNFg7zR"
   },
   "source": [
    "## Persiapan Data Test\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb92nf0_fph9"
   },
   "source": [
    "### Ekstraksi Fitur Data Test\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "4C1vr0nYfuM9",
    "outputId": "0bd33511-da07-4145-fcc7-8aec35cc25a8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(root_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, self.image_files[idx]\n",
    "\n",
    "test_dataset = TestDataset(test_dir, dinov2_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=EXTRACT_BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"üì¶ Extracting features dari {len(test_dataset)} gambar test...\")\n",
    "\n",
    "test_features_list = []\n",
    "test_filenames = []\n",
    "\n",
    "dinov2_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, filenames in tqdm(test_loader, desc=\"Ekstraksi Fitur Test\"):\n",
    "        images = images.to(device)\n",
    "        features = dinov2_model(images)\n",
    "        test_features_list.append(features.cpu().numpy())\n",
    "        test_filenames.extend(filenames)\n",
    "\n",
    "test_features = np.vstack(test_features_list)\n",
    "print(f\"‚úì Test features extracted: {test_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pynswn2dfvjk"
   },
   "source": [
    "## Prediksi\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "FpUF_j7TfyvO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load best classifier\n",
    "classifier.load_state_dict(torch.load('best_classifier_dinov2.pth'))\n",
    "classifier.eval()\n",
    "print(\"‚úì Best classifier loaded\")\n",
    "\n",
    "# Convert features ke tensor\n",
    "test_features_tensor = torch.from_numpy(test_features).float().to(device)\n",
    "\n",
    "# Prediksi\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    # Batch prediction untuk efisiensi\n",
    "    for i in tqdm(range(0, len(test_features_tensor), BATCH_SIZE), desc=\"Prediksi\"):\n",
    "        batch_features = test_features_tensor[i:i+BATCH_SIZE]\n",
    "        outputs = classifier(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(f\"‚úì Prediksi selesai untuk {len(all_predictions)} gambar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAEkAnt1f0b3"
   },
   "source": [
    "## Pembuatan File Submisi\n",
    "<hr style=\"border: 2px solid #8E7B6B; margin-top: 10px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-11T16:58:28.032Z"
    },
    "id": "mKP--c9ff2X4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_ids = [os.path.splitext(name)[0] for name in test_filenames]\n",
    "predicted_styles = [class_names[i] for i in all_predictions]\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'style': predicted_styles\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ File 'submission.csv' berhasil dibuat!\")\n",
    "print(f\"‚úì Total prediksi: {len(submission_df)}\")\n",
    "print(\"\\nüìÑ Preview submission:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"üìä Best Validation F1-Score: {best_f1:.4f}\")\n",
    "print(f\"üìÅ File output: submission.csv\")\n",
    "print(f\"üíæ Model tersimpan: best_classifier_dinov2.pth\")\n",
    "print(f\"üíæ Features tersimpan: train_features_dinov2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "O-Hj5tFmj_Wc",
    "RIyZL_vBa0hW",
    "7znM1V4Pcv0E",
    "oJymu9a-etyf",
    "wRqtlVRnfgaI",
    "Pynswn2dfvjk"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8456564,
     "sourceId": 13336759,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
